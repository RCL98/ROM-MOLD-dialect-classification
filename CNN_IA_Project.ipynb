{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_IA_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxM6GWAqyj8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import copy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import string\n",
        "import  random\n",
        "from spacy.lang.ro import Romanian\n",
        "from spacy.lang.ro.stop_words import STOP_WORDS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1iVgq_LMvTi",
        "colab_type": "code",
        "outputId": "d83d9ff0-9dcf-418d-bfb3-9dfa7126efcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd /content/drive/My Drive/Proiect_IA_3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Proiect_IA_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN4jfn3S9dYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(1024)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.deterministic = True  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLn3e1QGp66S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('train_data.csv', sep='\\t', encoding='utf-8', lineterminator='\\n', header = 0, names=['Id', 'Text', 'Label'])\n",
        "validation_data = pd.read_csv('valid_data.csv', sep='\\t', encoding='utf-8', lineterminator='\\n', header = 0, names=['Id', 'Text', 'Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ddsD3n9jkGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def full_texts(texts):\n",
        "  text = \" \"\n",
        "  for it in texts:\n",
        "    text += \" \".join(it)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wFonLEkkMNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = full_texts(train_data['Text'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9SwFkcVjbPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    Helper class that maps characters to unique indices and the other way around\n",
        "    \"\"\"\n",
        "    def __init__(self, text: str):\n",
        "        # PAD is a special character for padding shorter sequences \n",
        "        # in a mini-batch\n",
        "        # create a set out of all characters\n",
        "        characters_set = set([\"0\"]) \n",
        "        characters_set.update(text)\n",
        "        \n",
        "        #create a dictionary for characters\n",
        "        self.char_to_idx = {char:idx for (idx, char) \n",
        "                            in enumerate(characters_set)}\n",
        "        self.idx_to_char = {idx:char for (idx, char) \n",
        "                            in enumerate(characters_set)}\n",
        "   \n",
        "    def size(self):\n",
        "        return len(self.char_to_idx)\n",
        "      \n",
        "    def __str__(self):\n",
        "        return str(self.char_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9thlSu5kcTb",
        "colab_type": "code",
        "outputId": "04a170b2-d0c1-4eca-a631-d3481d27bcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "vocab = Vocabulary(text)\n",
        "print(\"Vocabulary size: \", vocab.size())\n",
        "print(\"Vocabulary: \\n\", vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size:  61\n",
            "Vocabulary: \n",
            " {'=': 0, 'l': 1, '!': 2, 'Y': 3, 'n': 4, ':': 5, 'E': 6, 'A': 7, ';': 8, 'g': 9, '<': 10, 'h': 11, 'o': 12, 'X': 13, 'w': 14, 'K': 15, 'b': 16, '#': 17, '@': 18, 'Z': 19, 'W': 20, '0': 21, 'k': 22, 'F': 23, 'B': 24, 'd': 25, 'p': 26, '*': 27, '&': 28, '|': 29, 'H': 30, '>': 31, 'R': 32, 'r': 33, '.': 34, '(': 35, 'N': 36, 'z': 37, 'i': 38, 'T': 39, ' ': 40, 'q': 41, 'C': 42, 'm': 43, 'U': 44, 't': 45, '$': 46, '}': 47, 'c': 48, 'j': 49, 'x': 50, '%': 51, 'e': 52, \"'\": 53, 'D': 54, 'S': 55, 'f': 56, 'y': 57, 'v': 58, 's': 59, 'a': 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBJbAqfiSGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_tensor(text: str, vocab: Vocabulary) -> torch.LongTensor:\n",
        "    \"\"\"\n",
        "    Convert a string to a Tensor with corresponding character indices\n",
        "    e.g. \"We have\" -> [48, 13,  2, 66, 56, 31, 13 \n",
        "    \"\"\"\n",
        "    text_indices = [vocab.char_to_idx[c] for c in text]\n",
        "  \n",
        "    return torch.tensor(text_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4EBb0nVQTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_collate(batch):\n",
        "  new_data = []\n",
        "  for item in batch:\n",
        "    new_data.append(F.pad(input=item[0], pad=(0, 2000 - item[0].shape[0]), mode='constant', value=vocab.char_to_idx['0']))\n",
        "  data = torch.stack(new_data, dim = 0)\n",
        "  target = torch.stack([torch.tensor(item[1]) for item in batch], dim = 0)\n",
        "  return [data, target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnzscKN3luU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextsDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, vocab = None, max_length = 1004):\n",
        "        self.X = texts\n",
        "        self.y = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_length\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        data = self.X[i]\n",
        "        data = text_to_tensor(data, self.vocab)\n",
        "        if self.y is not None:\n",
        "            y = self.y[i]\n",
        "            return (data, y)\n",
        "        else:\n",
        "            return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mpxPz5npaem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset = TextsDataset(train_data['Text'].tolist(), train_data[\"Label\"].tolist(),vocab, 1004)\n",
        "validing_dataset = TextsDataset(validation_data[\"Text\"].tolist(), validation_data[\"Label\"].tolist(),vocab, 1004)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jtRWzDiwhQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EzhzpGVqo-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=my_collate)\n",
        "validloader = DataLoader(validing_dataset, batch_size=batch_size, shuffle=True, drop_last = True, collate_fn=my_collate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHw8VDAD_bay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_Text(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size):\n",
        "        super(CNN_Text, self).__init__()\n",
        "        filter_sizes = [1,2,3,5]\n",
        "        num_filters = 36\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  \n",
        "        x = x.unsqueeze(1)  \n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  \n",
        "        logit = self.fc1(x)  \n",
        "        return torch.sigmoid(logit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DfrrGOXAeif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size_of_vocab = vocab.size()\n",
        "embedding_dim = 100\n",
        "\n",
        "#instantiate the model\n",
        "model_r =CNN_Text(size_of_vocab, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSXT8u52A4SD",
        "colab_type": "code",
        "outputId": "9c9ce621-5aa5-47d0-8b2b-676965651029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#architecture\n",
        "print(model_r)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model_r.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model_r):,} trainable parameters')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN_Text(\n",
            "  (embedding): Embedding(61, 100)\n",
            "  (convs1): ModuleList(\n",
            "    (0): Conv2d(1, 36, kernel_size=(1, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 36, kernel_size=(2, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 36, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (3): Conv2d(1, 36, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=144, out_features=1, bias=True)\n",
            ")\n",
            "The model has 45,989 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHpaoKSpBNub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model_r.parameters(), lr = 0.01)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model_r = model_r.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZDwmqRlBbYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    clip = 3\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    for inputs, labels in train_iterator:\n",
        "        #print(it)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        #print(\"retrive\")\n",
        "        output = model(inputs) \n",
        "        \n",
        "        #compute the loss\n",
        "        #print(\"loss\")\n",
        "        loss = criterion(output.squeeze(), labels.float())  \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        #print(\"acc\")\n",
        "        acc = binary_accuracy(output.squeeze(), labels)   \n",
        "        \n",
        "        #print(\"back\")\n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward() \n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)      \n",
        "        \n",
        "        #print(\"optim\")\n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()      \n",
        "    return epoch_loss / len(train_iterator), epoch_acc / len(train_iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nviwv9XB2Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, eval_iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    clip = 2\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for inputs, labels in eval_iterator:\n",
        "\n",
        "            #retrieve text and no. of words\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            output= model(inputs)\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            test_loss = criterion(output.squeeze(), labels.float())\n",
        "            acc = binary_accuracy(output.squeeze(), labels) \n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += test_loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(eval_iterator), epoch_acc / len(eval_iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Th5uzGB94j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model_r, trainloader, optimizer, criterion)\n",
        "    \n",
        "    print(\"Epoch: \", epoch)\n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model_r, validloader, criterion)\n",
        "     \n",
        "   #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model_r.state_dict(), 'saved_weights_3.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJL1TjlMe8M5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_r.load_state_dict(torch.load(\"saved_weights_3.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FetelSjTOryl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_loss, target_acc = evaluate(model_r, target_iterator, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}